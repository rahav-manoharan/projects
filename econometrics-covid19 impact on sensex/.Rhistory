cor(huswif)
cov2cor(my.S)
install.packages("neuralnet")
library(neuralnet)
x1<-c(1, 0, 1, 0)
x2<-c(1, 1, 0, 0)
input<-cbind(x1,x2)
output<-c(0, 1, 1, 0)
traindata<-cbind(input,output)
colnames(traindata)=c("x1","x2","Output")
model_net<-
neuralnet(Output~x1+x2,traindata,hidden=2,threshold=0.01,
linear.output=TRUE)
plot(model_net)
results<-compute(model_net,input)
view(results$model_net.result)
view(results$model_net.result)
results$model_net.result
View(results)
view(results$net.result)
view(results$net.result)
results$net.result
# install.packages("neuralnet")
library(neuralnet)
x1<-c(1, 0, 1, 0)
x2<-c(1, 1, 0, 0)
input<-cbind(x1,x2)
output<-c(0, 1, 1, 0)
traindata<-cbind(input,output)
colnames(traindata)=c("x1","x2","Output")
model_net<-
neuralnet(Output~x1+x2,traindata,hidden=2,threshold=0.01,
linear.output=TRUE)
plot(model_net)
results<-compute(model_net,input)
results$net.result
results
model_net<-
neuralnet(Output~x1+x2,traindata,hidden=2,threshold=0.01,
linear.output=TRUE)
plot(model_net)
results<-compute(model_net,input)
results$net.result
results
input<-cbind(x1,x2)
output<-c(0, 1, 1, 0)
traindata<-cbind(input,output)
colnames(traindata)=c("x1","x2","Output")
model_net<-
neuralnet(Output~x1+x2,traindata,hidden=2,threshold=0.01,
linear.output=TRUE)
plot(model_net)
results<-compute(model_net,input)
results$net.result
results
x1<-c(1, 0, 1, 0)
x2<-c(1, 1, 0, 0)
input<-cbind(x1,x2)
output<-c(0, 1, 1, 0)
traindata<-cbind(input,output)
colnames(traindata)=c("x1","x2","Output")
model_net<-
neuralnet(Output~x1+x2,traindata,hidden=2,threshold=0.01,
linear.output=TRUE)
plot(model_net)
results<-compute(model_net,input)
results$net.result
results
# install.packages("neuralnet")
library(neuralnet)
x1<-c(1, 0, 1, 0)
x2<-c(1, 1, 0, 0)
input<-cbind(x1,x2)
output<-c(0, 1, 1, 0)
traindata<-cbind(input,output)
colnames(traindata)=c("x1","x2","Output")
model_net<-
neuralnet(Output~x1+x2,traindata,hidden=2,threshold=0.01,
linear.output=TRUE)
plot(model_net)
results<-compute(model_net,input)
results$net.result
results
# install.packages("neuralnet")
library(neuralnet)
# install.packages("neuralnet")
library(neuralnet)
x1<-c(1, 0, 1, 0)
x2<-c(1, 1, 0, 0)
input<-cbind(x1,x2)
output<-c(0, 1, 1, 0)
traindata<-cbind(input,output)
colnames(traindata)=c("x1","x2","Output")
model_net<-
neuralnet(Output~x1+x2,traindata,hidden=2,threshold=0.01,
linear.output=TRUE)
results<-compute(model_net,input)
results$net.result
results
install.packages("neuralnet")
install.packages("neuralnet")
results
# install.packages("neuralnet")
library(neuralnet)
x1<-c(1, 0, 1, 0)
x2<-c(1, 1, 0, 0)
input<-cbind(x1,x2)
output<-c(0, 1, 1, 0)
traindata<-cbind(input,output)
colnames(traindata)=c("x1","x2","Output")
model_net<-
neuralnet(Output~x1+x2,traindata,hidden=2,threshold=0.01,
linear.output=TRUE)
plot(model_net)
results<-compute(model_net,input)
results$net.result
results
library(neuralnet)
x1<-c(1, 0, 1, 0)
x2<-c(1, 1, 0, 0)
input<-cbind(x1,x2)
output<-c(0, 1, 1, 0)
traindata<-cbind(input,output)
colnames(traindata)=c("x1","x2","Output")
model_net<-
neuralnet(Output~x1+x2,traindata,hidden=2,threshold=0.01,
linear.output=TRUE)
plot(model_net)
results<-compute(model_net,input)
results$net.result
results
# install.packages("neuralnet")
library(neuralnet)
x1<-c(1, 0, 1, 0)
x2<-c(1, 1, 0, 0)
input<-cbind(x1,x2)
output<-c(0, 1, 1, 0)
traindata<-cbind(input,output)
colnames(traindata)=c("x1","x2","Output")
model_net<-
neuralnet(output~x1+x2,traindata,hidden=2,threshold=0.01,
linear.output=TRUE)
plot(model_net)
results<-compute(model_net,input)
results
x1<-c(1, 0, 1, 0)
x2<-c(1, 1, 0, 0)
input<-cbind(x1,x2)
output<-c(0, 1, 1, 0)
traindata<-cbind(input,output)
colnames(traindata)=c("x1","x2","Output")
model_net<-
neuralnet(output~x1+x2,traindata,hidden=2,threshold=0.01,
linear.output=TRUE)
plot(model_net)
results<-compute(model_net,input)
# results$net.result
results
x1<-c(1, 0, 1, 0)
x2<-c(1, 1, 0, 0)
input<-cbind(x1,x2)
output<-c(0, 1, 1, 0)
traindata<-cbind(input,output)
colnames(traindata)=c("x1","x2","Output")
model_net<-
neuralnet(output~x1+x2,traindata,hidden=2,threshold=0.01,
linear.output=TRUE)
plot(model_net)
results<-compute(model_net,input)
results
View(results$net.result)
cars.data <- mtcars[,c(1,3,4,5,6,7)]
S <- var(cars.data)
eigen(S)
lam <- eigen(S)$values
s
S
P
p
D <- diag(lam)
P <-  eigen(S)$vectors
round( P %*% D %*% t(P) - S, 5)
round( t(P) %*% P , 5)
P
prcomp(S)
var(cars.data)
var(cars.data)
eigen(cars.data)
eigen(var(cars.data))
summary(prcomp(S))
library(MVA)
heptathlon
heptathlon$hurdles <- with(heptathlon, max(hurdles)-hurdles)
heptathlon$run200m <- with(heptathlon, max(run200m)-run200m)
heptathlon$run800m <- with(heptathlon, max(run800m)-run800m)
score <- which(colnames(heptathlon) == "score")
round(cor(heptathlon[,-score]), 2)
plot(heptathlon[,-score], pch = ".", cex = 1.5)
heptathlon <- heptathlon[-grep("PNG", rownames(heptathlon)),]
score <- which(colnames(heptathlon) == "score")
round(cor(heptathlon[,-score]), 2)
plot(heptathlon[,-score], pch = ".", cex = 1.5)
op <- options(digits = 2)
heptathlon_pca <- prcomp(heptathlon[, -score], scale = TRUE)
print(heptathlon_pca)
summary(heptathlon_pca)
a1 <- heptathlon_pca$rotation[,1]
center <- heptathlon_pca$center
scale <- heptathlon_pca$scale
hm <- as.matrix(heptathlon[,-score])
drop(scale(hm, center = center, scale = scale) %*%
heptathlon_pca$rotation[,1])
predict(heptathlon_pca)[,1]
sdev <- heptathlon_pca$sdev
prop12 <- round(sum(sdev[1:2]^2)/sum(sdev^2)*100, 0)
prop1 <- round(sdev[1]^2/sum(sdev^2)*100, 0)
plot(heptathlon_pca, main = "")
cor(heptathlon$score, -1 * heptathlon_pca$x[,1])
plot(heptathlon$score, -1 * heptathlon_pca$x[,1])
sd(c(1,2,3,4,5))
X <- matrix( c(3, 4 ,  4 , 6 , 1,
5 , 1 , 1 , 7 , 3,
6 , 2 , 0 , 2 , 6 ,
1 , 1 , 1 , 0 , 3 ,
4 , 7 , 3 , 6 , 2 ,
2,  2 , 5 , 1 , 0 ,
0 , 4 , 1 , 1 , 1 ,
0 , 6 , 4 , 3 , 5 ,
7 , 6 , 5 , 1 , 4 ,
2 , 1 , 4 , 3 , 1),
10, 5, byrow=T)
(D <- dist(X))
(D <- dist(X))
#apply classical scaling
cmdscale(D, k = 9, eig = TRUE)
round(cmdscale(D, k = 9, eig = TRUE), 3)
round(cmdscale(D, k = 9, eig = TRUE)$eig, 3)
dist(cmdscale(D, k = 5))
max(abs(dist(X) - dist(cmdscale(D, k = 5))))
max(abs(dist(X) - dist(cmdscale(D, k = 4))))
max(abs(dist(X) - dist(cmdscale(D, k = 3))))
abs(prcomp(X)$x)
abs(cmdscale(D, k = 5))
# check the duality of classical MDS with Euclidean distances and PCA
max(abs(prcomp(X)$x) - abs(cmdscale(D, k = 5)))
S_m <- dist(X, method = "manhatten")
S_m <- dist(X, method = "manhattan")
S_m
eigen(S_m)
# Now implement MDS with Manhattan (city-block) distance
X_m <- cmdscale(dist(X, method = "manhattan"), k = nrow(X) - 1, eig = TRUE)
X_m
round(X_m$eig, 4)
(X_eigen <- X_m$eig)
cumsum(abs(X_eigen)) / sum(abs(X_eigen))
cumsum(X_eigen^2) / sum(X_eigen^2)
cumsum(1:10)
##### Ex: classical multidimensional scaling to non-Euclidean distances, we shall use the airline distances between ten US cities
library(MVA)
"airline.dist" <-
structure(.Data = list(c(0, 587, 1212, 701, 1936, 604, 748, 2139, 2181, 543
, c(587, 0, 920, 940, 1745, 1188, 713, 1858, 1737, 597)
, c(1212, 920, 0, 879, 831, 1726, 1631, 949, 1021, 1494)
, c(701, 940, 879, 0, 1374, 968, 1420, 1645, 1891, 1220)
, c(1936, 1745, 831, 1374, 0, 2339, 2451, 347, 959, 2300)
, c(604, 1188, 1726, 968, 2339, 0, 1092, 2594, 2734, 923)
, c(748, 713, 1631, 1420, 2451, 1092, 0, 2571, 2408, 205)
, c(2139, 1858, 949, 1645, 347, 2594, 2571, 0, 678, 2442)
, c(218, 1737, 1021, 1891, 959, 2734, 2408, 678, 0, 2329)
, c(543, 597, 1494, 1220, 2300, 923, 205, 2442, 2329, 0))
, names = c("ATL", "ORD", "DEN", "HOU", "LAX", "MIA",
"JFK", "SFO", "SEA", "IAD")
, row.names = c("ATL", "ORD", "DEN", "HOU", "LAX", "MIA",
"JFK", "SFO", "SEA", "IAD")
, class = "data.frame"))
airdist <- as.dist(as.matrix(airline.dist))
tmp <- airdist
airdist <- as.data.frame(as.matrix(airdist))
htab <- HSAURtable(airdist)
htab$data[upper.tri(htab$data)] <- " "
toLatex(htab, pcol = 1, xname = "airdist",
caption = "Airline distances between ten US cities.",
label = "ch:MDS:airdist:tab", rownames = TRUE)
airdist <- as.dist(as.matrix(airline.dist))
airdist <- as.dist(as.matrix(airline.dist))
X <- matrix( c(3, 4 ,  4 , 6 , 1,
5 , 1 , 1 , 7 , 3,
6 , 2 , 0 , 2 , 6 ,
1 , 1 , 1 , 0 , 3 ,
4 , 7 , 3 , 6 ,  2 ,
2,  2 ,  5 ,  1 ,  0,
0 , 4 , 1 ,  1 , 1 ,
0 , 6 , 4 , 3 , 5 ,
7 , 6 , 5 , 1 , 4 ,
2 , 1 , 4 , 3 , 1),
10, 5, byrow=T)
(D <- dist(X))
#apply classical scaling
cmdscale(D, k = 9, eig = TRUE)
# P=5 APPEARS TO BE ENOUGH
# To confirm that the 5-dimensional solution achieves complete
#recovery of the observed distance matrix.
max(abs(dist(X) - dist(cmdscale(D, k = 5))))
# check the duality of classical MDS with Euclidean distances and PCA
max(abs(prcomp(X)$x) - abs(cmdscale(D, k = 5)))
# Now implement MDS with Manhattan (city-block) distance
X_m <- cmdscale(dist(X, method = "manhattan"), k = nrow(X) - 1, eig = TRUE)
round(X_m$eig, 4)
(X_eigen <- X_m$eig)
cumsum(abs(X_eigen)) / sum(abs(X_eigen))
cumsum(X_eigen^2) / sum(X_eigen^2)
##### Ex: classical multidimensional scaling to non-Euclidean distances, we shall use the airline distances between ten US cities
library(MVA)
"airline.dist" <-
structure(.Data = list(c(0, 587, 1212, 701, 1936, 604, 748, 2139, 2181, 543)
, c(587, 0, 920, 940, 1745, 1188, 713, 1858, 1737, 597)
, c(1212, 920, 0, 879, 831, 1726, 1631, 949, 1021, 1494)
, c(701, 940, 879, 0, 1374, 968, 1420, 1645, 1891, 1220)
, c(1936, 1745, 831, 1374, 0, 2339, 2451, 347, 959, 2300)
, c(604, 1188, 1726, 968, 2339, 0, 1092, 2594, 2734, 923)
, c(748, 713, 1631, 1420, 2451, 1092, 0, 2571, 2408, 205)
, c(2139, 1858, 949, 1645, 347, 2594, 2571, 0, 678, 2442)
, c(218, 1737, 1021, 1891, 959, 2734, 2408, 678, 0, 2329)
, c(543, 597, 1494, 1220, 2300, 923, 205, 2442, 2329, 0)
)
, names = c("ATL", "ORD", "DEN", "HOU", "LAX", "MIA",
"JFK", "SFO", "SEA", "IAD")
, row.names = c("ATL", "ORD", "DEN", "HOU", "LAX", "MIA",
"JFK", "SFO", "SEA", "IAD")
, class = "data.frame"
)
airdist <- as.dist(as.matrix(airline.dist))
tmp <- airdist
airdist <- as.data.frame(as.matrix(airdist))
htab <- HSAURtable(airdist)
htab$data[upper.tri(htab$data)] <- " "
toLatex(htab, pcol = 1, xname = "airdist",
caption = "Airline distances between ten US cities.",
label = "ch:MDS:airdist:tab", rownames = TRUE)
airdist <- tmp
airline_mds <- cmdscale(airdist, k = 9, eig = TRUE)
airline_mds$points
(lam <- airline_mds$eig)
cumsum(abs(lam)) / sum(abs(lam))
cumsum(lam^2) / sum(lam^2)
ch:MDS:airdist:plot
ch:MDS:airdist:plot
lim <- range(airline_mds$points[,1] * (-1)) * 1.2
plot(airline_mds$points[,1] * (-1), airline_mds$points[,2] * (-1),
type = "n", xlab = "Coordinate 1", ylab = "Coordinate 2",
xlim = lim, ylim = lim)
text(airline_mds$points[,1] *(-1), airline_mds$points[,2] * (-1),
labels(airdist), cex = 0.7)
data("skulls", package = "HSAUR2")
toLatex(HSAURtable(skulls), pcol = 3,
caption = "Measurements of four variables taken from Egyptian skulls of five periods.",
label = "ch:MDA:skulls:tab")
skulls_var <- tapply(1:nrow(skulls), skulls$epoch,
function(i) var(skulls[i,-1]))
S <- 0
skulls
head(skulls)
for (v in skulls_var) S <- S + 29 * v
(S <- S / 149)
skulls_cen <- tapply(1:nrow(skulls), skulls$epoch,
function(i) apply(skulls[i,-1], 2, mean))
skulls_cen <- matrix(unlist(skulls_cen),
nrow = length(skulls_cen), byrow = TRUE)
skulls_mah <- apply(skulls_cen, 1,
function(cen) mahalanobis(skulls_cen, cen, S))
skulls_mah
cmdscale(skulls_mah, k = nrow(skulls_mah) - 1,
eig = TRUE)$eig
lim <- range(skulls_mds) * 1.2
## Exercise ####
data("watervoles", package = "HSAUR2")
tmp <- watervoles
colnames(watervoles) <- abbreviate(colnames(watervoles))
watervoles <- as.data.frame(watervoles)
htab <- HSAURtable(watervoles)
htab$data[upper.tri(htab$data)] <- " "
toLatex(htab, pcol = 1, xname = "watervoles",
caption = "Water voles data-dissimilarity matrix.",
label = "MDS-watervoles-tab",
rownames = TRUE)
watervoles <- tmp
cmdscale(watervoles, k = 9, eig = TRUE)
cumsum(abs(watervoles)) / sum(abs(watervoles))
lam <- cmdscale(watervoles, k = 9, eig = TRUE)$eig
cumsum(abs(lam)) / sum(abs(lam))
cumsum(lam^2) / sum(lam^2)
#Example 1
install.packages("conjoint")
#Example 1
# install.packages("conjoint")
library(conjoint)
data(ice)
print("Preferences of all respondents (preferences as ranking data):")
ls()
print(ipref)
print(ipref)
print(iprof)
print(ilevn)
Conjoint(ipref,iprof,ilevn,y.type="rank")
caPartUtilities(ipref,iprof,ilevn)
caTotalUtilities(ipref,iprof)
caImportance(ipref,iprof)
ShowAllUtilities(ipref,iprof,ilevn)
caSegmentation(y=ipref, x=iprof, c=2)
print(iprof)
print(ilevn)
Ipref_rating=caRankToScore(ipref)
print("Preferences of all respondents (preferences converted into rating data):")
Conjoint(Ipref_rating,iprof,ilevn,y.type="score")
Ipref_rating
ipref
# conjoint on tea data
data(tea)
ls()
########## conjoint on journey data ############################################
data(journey)
ls()
########### conjoint on chocolate data #########################################
data(chocolate)
ls()
print(tpref)
print(tprof)
print(tlevn)
Conjoint(tpref[21:30],tprof[21:30],tlevn[21:30],y.type="rank")
print(tpref)
print(tprof)
print(tlevn)
Conjoint(tpref[21:30],tprof,tlevn,y.type="rank")
Conjoint(tpref[21:30, ],tprof,tlevn,y.type="rank")
Conjoint(tpref,tprof,tlevn,y.type="rank")
Conjoint(tpref$Y[21:30],tprof,tlevn,y.type="rank")
Conjoint(tpref,tprof,tlevn,y.type="rank")
caPartUtilities(tpref,tprof,tlevn)
caTotalUtilities(tpref,tprof)
caImportance(tpref,tprof)
ShowAllUtilities(tpref,tprof,tlevn)
print(tprof)
caTotalUtilities(tpref,tprof)
caPartUtilities(tpref,tprof,tlevn)
caImportance(tpref,tprof)
ShowAllUtilities(tpref,tprof,tlevn)
setwd("C:/Users/ADMIN/Desktop/Rahav/IIMB/Term4/EFC")
library("foreign")
library("dplyr")
library("plm")
library("sandwich")
library("skedastic")
library("lmtest")
lec17=read.table("Cleaned data.csv")
lec17=read.table("Cleaned data.xlsx")
head(subset(lec17, subject==1))
lec17=read.table("Cleaned data.xlsx")
lec17=read.table("Cleaned data")
lec17=read.table("Cleaned dataxls")
lec17=read.table("Cleaned data.xls")
setwd("C:/Users/ADMIN/Desktop/Rahav/IIMB/Term4/EFC/project")
lec17=read.table("Cleaned data.xls")
lec17=read.table("Cleaned data.xlsx")
cdata=read.csv("Cleaned.csv")
cdata=read.csv("Cleaned.csv")
head(subset(cdata, subject==1))
head(subset(cdata))
head(cdata)
library(caret)
library(fastDummies)
library("fastDummies")
install.packages("fastDummies")
library("fastDummies")
cdata=read.csv("Cleaned.csv")
head(cdata)
View(cdata)
################################
#Data preparation
################################
dummy <- dummy_cols(cdata, select_columns = "Partial Lockdown imposed (Yes(1)/No(0))")
View(cdata)
################################
#Data preparation
################################
dummy <- dummy_cols(cdata, select_columns = "Partial.Lockdown.imposed..Yes.1..No.0..")
View(dummy)
################################
#Data preparation
################################
colnames(dummy$Partial.Lockdown.imposed..Yes.1..No.0..) <- "partial_lockdown"
################################
#Data preparation
################################
colnames(cdata$Partial.Lockdown.imposed..Yes.1..No.0..) <- "partial_lockdown"
################################
#Data preparation
################################
colnames(cdata) <- "partial_lockdown"
cdata=read.csv("Cleaned.csv")
head(cdata)
################################
#Data preparation
################################
colnames(cdata)[8] <- "partial_lockdown"
################################
#Data preparation
################################
colnames(cdata)[7:8] <- c("complete_lock", "partial_lock")
dummy <- dummy_cols(cdata, select_columns = "Partial.Lockdown.imposed..Yes.1..No.0..")
dummy <- dummy_cols(cdata, select_columns = "partial_lock")
cdata <- dummy_cols(cdata, select_columns = "partial_lock")
cdata <- dummy_cols(cdata, select_columns = "partial_lock")[-c(8)]
